{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os, sys\r\n",
    "from IPython.display import display\r\n",
    "from IPython.display import Image as _Imgdis\r\n",
    "from PIL import Image\r\n",
    "from numpy import asarray\r\n",
    "from matplotlib import image\r\n",
    "from matplotlib import pyplot\r\n",
    "\r\n",
    "\r\n",
    "blocked_X = [f for f in os.listdir(\"DataSet/Blocked\") if os.path.isfile(os.path.join(\"DataSet/Blocked\", f))]\r\n",
    "print(\"Working with {0} images\".format(len(blocked_X)))\r\n",
    "blocked_Y = len(blocked_X)\r\n",
    "\r\n",
    "free_X = [f for f in os.listdir(\"DataSet/Free\") if os.path.isfile(os.path.join(\"DataSet/Free\", f))]\r\n",
    "print(\"Working with {0} images\".format(len(free_X)))\r\n",
    "free_Y = len(free_X)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for x in range (0,(len(blocked_X))):\r\n",
    "    blocked_Y = [0] * len(blocked_X)\r\n",
    "    name = blocked_X[x]\r\n",
    "    image = Image.open(\"DataSet/Blocked\" + \"/\" + name)\r\n",
    "    #display(_Imgdis(filename= \"DataSet/Blocked\" + \"/\" + blocked_X[x], width=240, height=320))\r\n",
    "    blocked_X[x] = asarray(image)\r\n",
    "    #print(blocked_X[x].shape)\r\n",
    "    #print(blocked_Y[x])\r\n",
    "    \r\n",
    "    \r\n",
    "for x in range (0,(len(free_X))):\r\n",
    "    free_Y = [1] * len(free_X)\r\n",
    "    name = free_X[x]\r\n",
    "    image = Image.open(\"DataSet/free\" + \"/\" + name)\r\n",
    "    #display(_Imgdis(filename= \"DataSet/free\" + \"/\" + free_X[x], width=240, height=320))\r\n",
    "    free_X[x] = asarray(image)\r\n",
    "    #print(blocked_X[x].shape)\r\n",
    "    #print(free_Y[x])\r\n",
    "    \r\n",
    "    \r\n",
    "dataset_X = np.concatenate([blocked_X, free_X])\r\n",
    "dataset_Y = np.concatenate([blocked_Y, free_Y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, Flatten,Conv2D , MaxPooling2D, Dropout\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "\r\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "\r\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "\r\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(256, activation=\"relu\"))\r\n",
    "model.add(Dense(128, activation=\"relu\"))\r\n",
    "model.add(Dense(64, activation=\"relu\"))\r\n",
    "model.add(Dense(32, activation=\"relu\"))\r\n",
    "model.add(Dense(16, activation=\"relu\"))\r\n",
    "model.add(Dense( 2, activation=\"softmax\"))\r\n",
    "\r\n",
    "model.compile(optimizer='RMSProp', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\r\n",
    "model.summary() \r\n",
    "\r\n",
    "checkpoint_path = \"cp.ckpt\"\r\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
    "                                                 save_weights_only=True,\r\n",
    "                                                 verbose=1)\r\n",
    "\r\n",
    "model.fit(dataset_X, dataset_Y,batch_size=32, epochs=43, shuffle = True, callbacks=[cp_callback])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(dataset_X, dataset_Y)\r\n",
    "results = model.predict(dataset_X[40].reshape(-1, 224, 224, 3))\r\n",
    "model.save(\"mBot_KI.hdf5\")\r\n",
    "print(results)\r\n",
    "\r\n",
    "\r\n",
    "dataset_Y\r\n",
    "dataset_X"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}